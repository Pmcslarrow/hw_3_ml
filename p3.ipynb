{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.36846388  1.54362905]\n",
      " [ 0.13476095 -0.35808876]\n",
      " [-1.17397245  2.0546884 ]\n",
      " [ 0.12212715 -0.3837286 ]\n",
      " [-0.08095132 -1.53810042]]\n",
      "[1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "def convert_df_to_numpy(df, scaler):\n",
    "  y = df['label'].to_numpy().astype(np.int32)\n",
    "  X = scaler.transform(df.drop(columns=['label']).to_numpy())\n",
    "  return X, y\n",
    "\n",
    "center_surround_train_df = pd.read_csv(\"./center_surround_train.csv\")\n",
    "center_surround_test_df = pd.read_csv(\"./center_surround_test.csv\")\n",
    "center_surround_valid_df = pd.read_csv(\"./center_surround_valid.csv\")\n",
    "\n",
    "center_surround_scaler = StandardScaler()\n",
    "center_surround_scaler.fit(center_surround_train_df.drop(columns=['label']).to_numpy())\n",
    "\n",
    "center_surround_train_data = convert_df_to_numpy(center_surround_train_df, center_surround_scaler)\n",
    "center_surround_test_data = convert_df_to_numpy(center_surround_test_df, center_surround_scaler)\n",
    "center_surround_valid_data = convert_df_to_numpy(center_surround_valid_df, center_surround_scaler)\n",
    "\n",
    "print(center_surround_train_data[0][:5])\n",
    "print(center_surround_train_data[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 2\n",
    "OUTPUT_DIM = 1\n",
    "HIDDEN_NODES = 4\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Entered the weight and biases initialization**\n",
      "\n",
      "**Entered the forward pass**\n",
      "[[0.69484065]\n",
      " [0.74270986]\n",
      " [0.72185353]\n",
      " [0.74122793]\n",
      " [0.69835022]\n",
      " [0.72956145]\n",
      " [0.76160363]\n",
      " [0.81369625]\n",
      " [0.77199206]\n",
      " [0.68348804]\n",
      " [0.78074368]\n",
      " [0.68143562]\n",
      " [0.8237822 ]\n",
      " [0.73187005]\n",
      " [0.70815021]\n",
      " [0.75842824]\n",
      " [0.83546116]\n",
      " [0.7587434 ]\n",
      " [0.72663823]\n",
      " [0.7316732 ]\n",
      " [0.78422306]\n",
      " [0.75746248]\n",
      " [0.7902659 ]\n",
      " [0.81686218]\n",
      " [0.65023317]\n",
      " [0.68252027]\n",
      " [0.84009811]\n",
      " [0.77957029]\n",
      " [0.7037367 ]\n",
      " [0.77027083]\n",
      " [0.75728228]\n",
      " [0.80536863]\n",
      " [0.60641199]\n",
      " [0.69382853]\n",
      " [0.75476992]\n",
      " [0.70815286]\n",
      " [0.62829784]\n",
      " [0.62583743]\n",
      " [0.74872029]\n",
      " [0.61798252]\n",
      " [0.8033643 ]\n",
      " [0.7212943 ]\n",
      " [0.81556583]\n",
      " [0.75824362]\n",
      " [0.85173041]\n",
      " [0.64916072]\n",
      " [0.83071876]\n",
      " [0.79168904]\n",
      " [0.83654859]\n",
      " [0.83955405]\n",
      " [0.74125749]\n",
      " [0.76216256]\n",
      " [0.70740951]\n",
      " [0.72365679]\n",
      " [0.63871447]\n",
      " [0.67399582]\n",
      " [0.80056372]\n",
      " [0.60716506]\n",
      " [0.76451817]\n",
      " [0.779166  ]\n",
      " [0.75662317]\n",
      " [0.72956457]\n",
      " [0.68433962]\n",
      " [0.75760761]\n",
      " [0.75315526]\n",
      " [0.73585065]\n",
      " [0.73692597]\n",
      " [0.59260429]\n",
      " [0.85252832]\n",
      " [0.69764275]\n",
      " [0.85698288]\n",
      " [0.74246434]\n",
      " [0.73604351]\n",
      " [0.72392661]\n",
      " [0.82723751]\n",
      " [0.77920363]\n",
      " [0.75249462]\n",
      " [0.70583557]\n",
      " [0.61090206]\n",
      " [0.70042037]\n",
      " [0.7356569 ]\n",
      " [0.72056699]\n",
      " [0.74697361]\n",
      " [0.6670713 ]\n",
      " [0.69739564]\n",
      " [0.80765511]\n",
      " [0.59416239]\n",
      " [0.70709983]\n",
      " [0.83489472]\n",
      " [0.834881  ]\n",
      " [0.74627645]\n",
      " [0.81347575]\n",
      " [0.76433309]\n",
      " [0.72547097]\n",
      " [0.79469171]\n",
      " [0.80649471]\n",
      " [0.59647325]\n",
      " [0.77608584]\n",
      " [0.83485809]\n",
      " [0.74546783]\n",
      " [0.71364405]\n",
      " [0.63634113]\n",
      " [0.72534264]\n",
      " [0.7809729 ]\n",
      " [0.75370485]\n",
      " [0.76627363]\n",
      " [0.64532558]\n",
      " [0.72797532]\n",
      " [0.75881395]\n",
      " [0.68961017]\n",
      " [0.78401798]\n",
      " [0.58258893]\n",
      " [0.7223169 ]\n",
      " [0.71132653]\n",
      " [0.69453204]\n",
      " [0.80164426]\n",
      " [0.82756636]\n",
      " [0.81151531]\n",
      " [0.76322624]\n",
      " [0.74849164]\n",
      " [0.73098934]\n",
      " [0.66754718]\n",
      " [0.69618157]\n",
      " [0.68472028]\n",
      " [0.69821146]\n",
      " [0.74841341]\n",
      " [0.69999646]\n",
      " [0.82571214]\n",
      " [0.74753303]\n",
      " [0.62220777]\n",
      " [0.77111567]\n",
      " [0.79491144]\n",
      " [0.80191753]\n",
      " [0.68600104]\n",
      " [0.72504906]\n",
      " [0.84309807]\n",
      " [0.83999709]\n",
      " [0.75849874]\n",
      " [0.74988389]\n",
      " [0.74454246]\n",
      " [0.6426627 ]\n",
      " [0.60815493]\n",
      " [0.81380159]\n",
      " [0.70020154]\n",
      " [0.66288537]\n",
      " [0.71936355]\n",
      " [0.68463291]\n",
      " [0.79741987]\n",
      " [0.78664088]\n",
      " [0.76565445]\n",
      " [0.74706157]\n",
      " [0.64958068]\n",
      " [0.73091695]\n",
      " [0.75748115]\n",
      " [0.77463933]\n",
      " [0.77196627]\n",
      " [0.702889  ]\n",
      " [0.81194746]\n",
      " [0.74770685]\n",
      " [0.66516688]\n",
      " [0.7314803 ]\n",
      " [0.83495457]\n",
      " [0.80471832]\n",
      " [0.71650879]\n",
      " [0.73335012]\n",
      " [0.74585292]\n",
      " [0.74702356]\n",
      " [0.80869482]\n",
      " [0.73351973]\n",
      " [0.71596465]\n",
      " [0.80901214]\n",
      " [0.73347105]\n",
      " [0.74334757]\n",
      " [0.79795256]\n",
      " [0.75399047]\n",
      " [0.81836186]\n",
      " [0.69056284]\n",
      " [0.66811913]\n",
      " [0.85161051]\n",
      " [0.70124211]\n",
      " [0.64803206]\n",
      " [0.75148133]\n",
      " [0.74762832]\n",
      " [0.6335788 ]\n",
      " [0.79749632]\n",
      " [0.79350411]\n",
      " [0.7986122 ]\n",
      " [0.64655749]\n",
      " [0.81620609]\n",
      " [0.72429596]\n",
      " [0.61348191]\n",
      " [0.82457918]\n",
      " [0.77591687]\n",
      " [0.75080679]\n",
      " [0.65455105]\n",
      " [0.65572506]\n",
      " [0.73766711]\n",
      " [0.64778513]\n",
      " [0.67727641]\n",
      " [0.64780227]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.FeedForwardNeuralNetwork at 0x16d484520>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeedForwardNeuralNetwork:\n",
    "  def __init__(self, train_data, test_data, valid_data, input_dim, output_dim, hidden_nodes, learning_rate, hidden_activation=\"sigmoid\", output_activation='sigmoid'):\n",
    "    self.train_data = train_data\n",
    "    self.test_data = test_data\n",
    "    self.valid_data = valid_data\n",
    "    self.input_dim = input_dim\n",
    "    self.output_dim = output_dim\n",
    "    self.hidden_nodes = hidden_nodes\n",
    "    self.learning_rate = learning_rate\n",
    "    self.hidden_activation = self.sigmoid if hidden_activation == \"sigmoid\" else None \n",
    "    self.output_activation = self.sigmoid if output_activation == \"sigmoid\" else None \n",
    "\n",
    "    self.W_input_hidden = None\n",
    "    self.W_hidden_output = None\n",
    "    self.B_input_hidden = None\n",
    "    self.B_hidden_output = None\n",
    "\n",
    "    self.initialize_weights_and_biases()\n",
    "    self.forward()\n",
    "  \n",
    "  def sigmoid(self, x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "  \n",
    "  def softmax(self, x):\n",
    "    return np.exp(x)/sum(np.exp(x))\n",
    "\n",
    "  def initialize_weights_and_biases(self):\n",
    "    \"\"\"\n",
    "    Initialize weights and biases for input-hidden and hidden-output layers.\n",
    "\n",
    "    Shapes:\n",
    "      Input -> Hidden:  (2, 4) weights, (4,) biases\n",
    "      Hidden -> Output: (4, 2) weights, (2,) biases\n",
    "    \"\"\"\n",
    "    print(\"**Entered the weight and biases initialization**\")\n",
    "    self.W_input_hidden = np.random.random((self.input_dim, self.hidden_nodes))\n",
    "    self.B_input_hidden = np.zeros((self.hidden_nodes,))\n",
    "\n",
    "    self.W_hidden_output = np.random.random((self.hidden_nodes, self.output_dim))\n",
    "    self.B_hidden_output = np.zeros((self.output_dim))\n",
    "\n",
    "    return\n",
    "\n",
    "  def forward(self):\n",
    "    \"\"\"\n",
    "    Perform forward pass through hidden and output layers with activations.\n",
    "\n",
    "    Output (first 3 points):\n",
    "      [[0.69484065]\n",
    "      [0.74270986]\n",
    "      [0.72185353]]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n**Entered the forward pass**\")\n",
    "\n",
    "    # Input to hidden layer with activation \n",
    "    train_features = self.train_data[0]\n",
    "    hidden_logits = np.dot(train_features, self.W_input_hidden) + self.B_input_hidden\n",
    "    hidden_output = self.hidden_activation(hidden_logits)\n",
    "    \n",
    "    # The output from the first layer (hidden_output) is now the input into the next layer\n",
    "    output_logits = np.dot(hidden_output, self.W_hidden_output) + self.B_hidden_output\n",
    "    output = self.output_activation(output_logits)\n",
    "    return output\n",
    "  \n",
    "  def binary_cross_entropy_loss(self, predictions, actuals):\n",
    "    \"\"\"\n",
    "    UPDATE ME\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    for i in range(predictions.shape[0]):\n",
    "        actual = actuals[i]\n",
    "        pred = predictions[i]\n",
    "        internal = actual * np.log(pred) + (1 - actual) * np.log(1 - pred)\n",
    "        loss += internal  \n",
    "    return -loss / predictions.shape[0]\n",
    "\n",
    "\n",
    "FeedForwardNeuralNetwork(\n",
    "  train_data=center_surround_train_data,\n",
    "  test_data=center_surround_test_data,\n",
    "  valid_data=center_surround_valid_data,\n",
    "  input_dim=INPUT_DIM,\n",
    "  output_dim=OUTPUT_DIM,\n",
    "  hidden_nodes=HIDDEN_NODES,\n",
    "  learning_rate=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
