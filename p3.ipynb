{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.36846388  1.54362905]\n",
      " [ 0.13476095 -0.35808876]\n",
      " [-1.17397245  2.0546884 ]\n",
      " [ 0.12212715 -0.3837286 ]\n",
      " [-0.08095132 -1.53810042]]\n",
      "[1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "def convert_df_to_numpy(df, scaler):\n",
    "  y = df['label'].to_numpy().astype(np.int32)\n",
    "  X = scaler.transform(df.drop(columns=['label']).to_numpy())\n",
    "  return X, y\n",
    "\n",
    "center_surround_train_df = pd.read_csv(\"./center_surround_train.csv\")\n",
    "center_surround_test_df = pd.read_csv(\"./center_surround_test.csv\")\n",
    "center_surround_valid_df = pd.read_csv(\"./center_surround_valid.csv\")\n",
    "\n",
    "center_surround_scaler = StandardScaler()\n",
    "center_surround_scaler.fit(center_surround_train_df.drop(columns=['label']).to_numpy())\n",
    "\n",
    "center_surround_train_data = convert_df_to_numpy(center_surround_train_df, center_surround_scaler)\n",
    "center_surround_test_data = convert_df_to_numpy(center_surround_test_df, center_surround_scaler)\n",
    "center_surround_valid_data = convert_df_to_numpy(center_surround_valid_df, center_surround_scaler)\n",
    "\n",
    "print(center_surround_train_data[0][:5])\n",
    "print(center_surround_train_data[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 2\n",
    "OUTPUT_DIM = 1\n",
    "HIDDEN_NODES = 2\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Entered the weight and biases initialization**\n",
      "Neuron q:  (200, 2)\n",
      "Neuron h:  (200, 2)\n",
      "Neuron z:  (200, 1)\n",
      "Neuron p:  (200, 1)\n",
      "Epoch (0/20) --- Training Error:  0.6981130235889921\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (2,200) and (1,) not aligned: 200 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/pmcslarrow/Desktop/NORTHWESTERN/Group Projects/hw_3_ml/p3.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m       \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch (\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m20\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m) --- Training Error: \u001b[39m\u001b[39m\"\u001b[39m, error\u001b[39m.\u001b[39mitem())\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackpropogate(predictions, actuals)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m FeedForwardNeuralNetwork(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m   train_data\u001b[39m=\u001b[39;49mcenter_surround_train_data,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m   test_data\u001b[39m=\u001b[39;49mcenter_surround_test_data,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m   valid_data\u001b[39m=\u001b[39;49mcenter_surround_valid_data,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m   input_dim\u001b[39m=\u001b[39;49mINPUT_DIM,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m   output_dim\u001b[39m=\u001b[39;49mOUTPUT_DIM,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m   hidden_nodes\u001b[39m=\u001b[39;49mHIDDEN_NODES,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m   learning_rate\u001b[39m=\u001b[39;49mLEARNING_RATE\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/pmcslarrow/Desktop/NORTHWESTERN/Group Projects/hw_3_ml/p3.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB_hidden_output \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize_weights_and_biases()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n",
      "\u001b[1;32m/Users/pmcslarrow/Desktop/NORTHWESTERN/Group Projects/hw_3_ml/p3.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_entropy_loss(predictions, actuals)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch (\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m20\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m) --- Training Error: \u001b[39m\u001b[39m\"\u001b[39m, error\u001b[39m.\u001b[39mitem())\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackpropogate(predictions, actuals)\n",
      "\u001b[1;32m/Users/pmcslarrow/Desktop/NORTHWESTERN/Group Projects/hw_3_ml/p3.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m output_layer_delta \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatmul(output_error, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mderivative_sigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_z))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39m# Derivative (dz/dh) where h is hidden layer activation\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m dW_hidden_output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_h\u001b[39m.\u001b[39;49mT, output_layer_delta) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m# Derivative (dh/dq) where q is pre-activation of hidden layer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pmcslarrow/Desktop/NORTHWESTERN/Group%20Projects/hw_3_ml/p3.ipynb#W3sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m hidden_error \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(output_layer_delta, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_hidden_output\u001b[39m.\u001b[39mT) \n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,200) and (1,) not aligned: 200 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "class FeedForwardNeuralNetwork:\n",
    "  def __init__(self, train_data, test_data, valid_data, input_dim, output_dim, hidden_nodes, learning_rate, hidden_activation=\"sigmoid\", output_activation='sigmoid'):\n",
    "    self.train_data = train_data\n",
    "    self.test_data = test_data\n",
    "    self.valid_data = valid_data\n",
    "    self.input_dim = input_dim\n",
    "    self.output_dim = output_dim\n",
    "    self.hidden_nodes = hidden_nodes\n",
    "    self.learning_rate = learning_rate\n",
    "    self.hidden_activation = self.sigmoid if hidden_activation == \"sigmoid\" else None \n",
    "    self.output_activation = self.sigmoid if output_activation == \"sigmoid\" else None \n",
    "\n",
    "    self.W_input_hidden = None\n",
    "    self.W_hidden_output = None\n",
    "    self.B_input_hidden = None\n",
    "    self.B_hidden_output = None\n",
    "\n",
    "    self.initialize_weights()\n",
    "    self.train()\n",
    "  \n",
    "  def sigmoid(self, x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "  \n",
    "  def derivative_sigmoid(self, x):\n",
    "    return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "  \n",
    "  def cross_entropy_loss(self, predictions, actuals):\n",
    "    loss = 0.0\n",
    "    for i in range(predictions.shape[0]):\n",
    "        actual = actuals[i]\n",
    "        pred = predictions[i]\n",
    "        internal = actual * np.log(pred) + (1 - actual) * np.log(1 - pred)\n",
    "        loss += internal  \n",
    "    return -loss / predictions.shape[0]\n",
    "  \n",
    "  def derivative_entropy_loss(self, predictions, actuals):\n",
    "    gradients = np.zeros((predictions.shape[0], ))\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "      y = actuals[i]\n",
    "      p = predictions[i]\n",
    "      if y == 1:\n",
    "          gradients[i] = -1 / p \n",
    "      else:\n",
    "          gradients[i] = -(1 / (1 - p)) \n",
    "    return gradients\n",
    "\n",
    "  def initialize_weights(self):\n",
    "    \"\"\"\n",
    "    Initialize weights and biases for input-hidden and hidden-output layers.\n",
    "\n",
    "    Shapes:\n",
    "      Input -> Hidden:  (2, 4) weights\n",
    "      Hidden -> Output: (4, 2) weights\n",
    "    \"\"\"\n",
    "    self.W_input_hidden = np.random.randn(self.input_dim, self.hidden_nodes)\n",
    "    self.W_hidden_output = np.random.randn(self.hidden_nodes, self.output_dim)\n",
    "    return\n",
    "\n",
    "  def forward(self):\n",
    "    \"\"\"\n",
    "    Perform forward pass through hidden and output layers with activations.\n",
    "\n",
    "    Output (first 3 points):\n",
    "      [[0.69484065]\n",
    "      [0.74270986]\n",
    "      [0.72185353]]\n",
    "    \"\"\"\n",
    "    X = self.train_data[0]\n",
    "    self.n_q = np.dot(X, self.W_input_hidden)\n",
    "    self.n_h = self.sigmoid(self.n_q)\n",
    "    self.n_z = np.dot(self.n_h, self.W_hidden_output)\n",
    "    self.n_p = self.sigmoid(self.n_z)\n",
    "    return self.n_p\n",
    "\n",
    "  def backpropogate(self, predictions, target):\n",
    "    pass\n",
    "\n",
    "  def train(self):\n",
    "    for epoch in range(20):\n",
    "      predictions = self.forward()\n",
    "      actuals = self.train_data[1]\n",
    "      \n",
    "      error = self.cross_entropy_loss(predictions, actuals)\n",
    "      print(f\"Epoch ({epoch}/{20}) --- Training Error: \", error.item())\n",
    "\n",
    "      self.backpropogate(predictions, actuals)\n",
    "\n",
    "\n",
    "FeedForwardNeuralNetwork(\n",
    "  train_data=center_surround_train_data,\n",
    "  test_data=center_surround_test_data,\n",
    "  valid_data=center_surround_valid_data,\n",
    "  input_dim=INPUT_DIM,\n",
    "  output_dim=OUTPUT_DIM,\n",
    "  hidden_nodes=HIDDEN_NODES,\n",
    "  learning_rate=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
